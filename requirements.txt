torch>=2.3.0
transformers>=4.46.0
datasets>=2.20.0
accelerate>=0.34.0
deepspeed>=0.15.0
peft>=0.12.0
trl>=0.10.1
sentencepiece>=0.2.0
safetensors>=0.4.4
tokenizers>=0.20.0
huggingface_hub>=0.24.0
numpy>=1.26.0
packaging>=24.1
pyyaml>=6.0.2
tqdm>=4.66.4
einops>=0.8.0
scipy>=1.13.1
